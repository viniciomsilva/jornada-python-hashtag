{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25eb04b7",
   "metadata": {},
   "source": [
    "# Python IA | Artificial Intelligence and predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655a70f1",
   "metadata": {},
   "source": [
    "## Case | score de crédito dos clientes\n",
    "\n",
    "You've been hired by a bank to determine its customers' credit scores.  \n",
    "You need to analyze the bank's entire customer database and, based on it, create an AI model that can determine a new\n",
    "customer's credit score based on their data, such as: **Bad**; **Regular**; **Good**.\n",
    "\n",
    "---\n",
    "\n",
    "[pt_BR] Você foi contrato por um banco para conseguir definir o score de crédito dos clientes.  \n",
    "Você precisa analisar toda a base de dados de clientes do banco e, com base nela, criar um modelo de IA que consiga\n",
    "definir o score de crédito do novo cliente com base nos dados dele como: **Poor**; **Regular**; **Good**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4bfb1e",
   "metadata": {},
   "source": [
    "## Library Installation\n",
    "\n",
    "* By shell: `pip install pandas scikit-learn`\n",
    "* By Jupyter Notebook: `%pip install pandas scikit-learn`\n",
    "\n",
    "> NOTE: Install only once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71eb12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fd39d0",
   "metadata": {},
   "source": [
    "## Data preprocessing and AI | Flow\n",
    "\n",
    "In data preprocessing, understanding the challenge and the institution behind it shapes the filters for the most\n",
    "acceptable results. In this case, the model that best predicts customers' credit scores with an accuracy between 80% and\n",
    "100% is the most appropriate.\n",
    "\n",
    "**Project steps:**\n",
    "\n",
    "1. Import the libraries and database\n",
    "2. Prepare the database for AI\n",
    "3. Create the AI ​​models and train them to predict customers' credit scores\n",
    "4. Choose the best model (the one with the most accurate score)\n",
    "5. Use this model to make new predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff66d36e",
   "metadata": {},
   "source": [
    "### Flow | Import libs and databases\n",
    "\n",
    "**Databases:**  \n",
    "Since all databases are in the `../databases/` directory, you need to resolve the path for Pandas.\n",
    "* Customer data for AI training (`clients.csv` file)\n",
    "* New customer data for AI credit score prediction (`new_clients.csv` file)\n",
    "\n",
    "**IA Models**  \n",
    "In AI projects, it's always best to train more than one model simultaneously for comparison and to select the best model\n",
    "without bias.\n",
    "\n",
    "**Libs**\n",
    "* Pandas: processes data from CSV files into a Python structure\n",
    "* Scikit Learn\n",
    "  * Label Encoder: treat non-numeric data as numeric, the only formats accepted by AI models ([see documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder))\n",
    "  * KNeighbors Classifier: AI model that classifies a customer's credit score based on customers with similar characteristics, their \"neighbors\" ([see documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier))\n",
    "  * Random Forest Classifier: AI model that ranks customer scores based on random analysis of other customer information ([see documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier))\n",
    "  * Train Test Split *Method*: a method that divides the database into training data and test data, which are then further divided into analysis data and template data ([see documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split))\n",
    "  * Accuracy Score *Method*: a method that calculates the accuracy of the AI ​​model by comparing its response to the test analysis data with the test template ([see documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd75918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getcwd, path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1665355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_folder_path = path.join(path.dirname(getcwd()), \"databases\")\n",
    "df = pd.read_csv(path.join(db_folder_path, \"clients.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783b2353",
   "metadata": {},
   "source": [
    "Display the data and information for human preview, in order to understand the types present in the database and detect\n",
    "possible errors and lack of information for correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bbf34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ec34c1",
   "metadata": {},
   "source": [
    "### Flow | prepare the database for AI (Label Encoder)\n",
    "\n",
    "Preparing data for AI involves encoding non-numeric data into numeric data, as AI can only perform calculations with\n",
    "numeric data (obviously). To do this, you use the Label Encoder, which is responsible for encoding and decoding the data.\n",
    "\n",
    "The \"profissao,\" \"mix_credito,\" and \"comportamento_pagamento\" columns are object types in the database. Therefore, an\n",
    "encoder is created for each of them.\n",
    "\n",
    "```python\n",
    "profession_coder = LabelEncoder()  # \"profissao\" column coder\n",
    "credit_mix_coder = LabelEncoder()  # \"mix_credito\" column coder\n",
    "payment_behavior_coder = LabelEncoder()  # \"comportamento_pagamento\" column coder\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f12f203",
   "metadata": {},
   "outputs": [],
   "source": [
    "profession_coder = LabelEncoder()\n",
    "credit_mix_coder = LabelEncoder()\n",
    "payment_behavior_coder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53540076",
   "metadata": {},
   "source": [
    "Each encoder creates a \"map\" of the original data to the numeric value. It is from this mapping that the data can be\n",
    "easily transformed and reversed. Therefore, the Label Encoder process is practical.\n",
    "\n",
    "\n",
    "Example.:\n",
    "| professional value | transform(obj) -> num | invert(num) -> obj |\n",
    "| :----------------: | :-------------------: | :----------------: |\n",
    "| cientista          |                    1  | cientista          |\n",
    "| professor          |                    2  | professor          |\n",
    "| ...                |                   ... | ...                |\n",
    "| desenvolvedor      |                    n  | desenvolvedor      |\n",
    "\n",
    "\n",
    "```py\n",
    "# column \"profissao\" receives the original encoded value\n",
    "df[\"profissao\"] = profession_coder.fit_transform(df[\"profissao\"])  # transforme the value of the \"profissao\" column from object to number\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7682b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"profissao\"] = profession_coder.fit_transform(df[\"profissao\"])\n",
    "df[\"mix_credito\"] = credit_mix_coder.fit_transform(df[\"mix_credito\"])\n",
    "df[\"comportamento_pagamento\"] = payment_behavior_coder.fit_transform(df[\"comportamento_pagamento\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe694d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feb59fd",
   "metadata": {},
   "source": [
    "### Flow | prepare the database for AI (Train Test Split Database)\n",
    "\n",
    "Before starting to train AI models, the database needs to be divided.\n",
    "\n",
    "**How ​​will this division work?**\n",
    "For a better understanding, the database can be imagined as a Cartesian plane with an X and Y axes. In this analogy, the\n",
    "X information will be used to predict the Y values. X and Y will be divided again into two parts: X and Y for training\n",
    "and X and Y for testing. Thus, the following structure is obtained:\n",
    "\n",
    "* Training X: information that the AI ​​will use to predict the training Y values\n",
    "* Training Y: template information to train the AI's accuracy\n",
    "* Test X: information that, after training, will be used to determine the test Y values\n",
    "* Test Y: information to measure the AI ​​model's accuracy and determine the best model for the project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13b0bb9",
   "metadata": {},
   "source": [
    "**Reference who X and Y are**\n",
    "\n",
    "* Y is the column you want to predict\n",
    "* X are all other columns relevant to predicting Y\n",
    "\n",
    "```python\n",
    "y = df[\"score_credito\"]  # column \"score_credito\" that the AI ​​should predict\n",
    "X = df.drop(columns=[\"id_cliente\", \"score_credito\"])  # all other columns except \"id_cliente\" and \"score_credito\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa92feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"score_credito\"]\n",
    "X = df.drop(columns=[\"id_cliente\", \"score_credito\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6fb26b",
   "metadata": {},
   "source": [
    "**Separate into training and test data**\n",
    "\n",
    "* Training X to predict training Y\n",
    "* Training Y to train the AI\n",
    "* Test X to predict test Y\n",
    "* Test Y to measure the AI's prediction accuracy\n",
    "\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)  # test_size default = 0.25\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f1ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7684e550",
   "metadata": {},
   "source": [
    "> IMPORTANT!\n",
    "> Y data does not need to go through the LabelEncoder process\n",
    "> The ideal size of data reserved for testing should be between 20% and 30%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a2bfc1",
   "metadata": {},
   "source": [
    "## Instantiate and train IA models\n",
    "\n",
    "With the models imported, it's time to instantiate and train them. In each model's constructor, you can pass various \n",
    "calibration parameters. However, in this project, the models were used with the default calibration.\n",
    "\n",
    "```python\n",
    "clf = RandomForestClassifier()  # random forest classification model\n",
    "neigh = KNeighborsClassifier()  # nearest neighbor classification model\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f345fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "neigh = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362655f4",
   "metadata": {},
   "source": [
    "Here the training is done automatically, passing to each training model X and Y.\n",
    "\n",
    "```python\n",
    "clf.fit(X=X_train, y=y_train)  # fits the random classification modelo\n",
    "neigh.fit(X=X_train, y=y_train)  # fits the nearest neighbor classification model\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6541474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X=X_train, y=y_train)\n",
    "neigh.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515551e4",
   "metadata": {},
   "source": [
    "## Choosing the best AI model\n",
    "\n",
    "The model with the best accuracy in predicting customers' credit scores will be chosen.\n",
    "\n",
    "To calculate this, the model will attempt to predict the test value of Y using the test value of X. Its response will be \n",
    "stored. Then, the AI ​​prediction is compared with the original test value of Y, thus calculating its success rate.\n",
    "\n",
    "```python\n",
    "# the model predicts using X test\n",
    "pred_clf = clf.predict(X=X_test)\n",
    "pred_neigh = neigh.predict(X=X_test)\n",
    "\n",
    "# calculate the accuracy of each model by comparing its prediction with the test Y value\n",
    "accuracy_score(y_test, pred_clf)\n",
    "accuracy_score(y_test, pred_neigh)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caee9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_clf = clf.predict(X=X_test)\n",
    "pred_neigh = neigh.predict(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e74f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(accuracy_score(y_test, pred_clf))\n",
    "display(accuracy_score(y_test, pred_neigh))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c119894f",
   "metadata": {},
   "source": [
    "**In these circumstances:**\n",
    "\n",
    "* The random forest classification model had an accuracy of 83% (*chosen*)\n",
    "* The nearest neighbor classification model had an accuracy of 75%\n",
    "\n",
    "For this project, both are good values. But there's nothing stopping you from improving the model or testing others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f92505",
   "metadata": {},
   "source": [
    "## Use the chosen model for new predictions\n",
    "\n",
    "To use the chosen model to make new predictions, you need to follow the same steps as before regarding data processing.\n",
    "After processing the data, it can be used to calculate the credit scores of new customers.\n",
    "\n",
    "> NOTE: Here there is no way to separate the data into X and Y, as there is no Y. It is what will be discovered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7347bf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_clients = pd.read_csv(path.join(db_folder_path, \"new_clients.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4051f363",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(new_clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438380a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_clients[\"profissao\"] = profession_coder.fit_transform(new_clients[\"profissao\"])\n",
    "new_clients[\"mix_credito\"] = credit_mix_coder.fit_transform(new_clients[\"mix_credito\"])\n",
    "new_clients[\"comportamento_pagamento\"] = payment_behavior_coder.fit_transform(new_clients[\"comportamento_pagamento\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544bb57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(clf.predict(new_clients))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
